{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# GOOGLE COLAB SETUP - Mount Drive & Extract Data\n",
        "# ================================================\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clone the repository\n",
        "!git clone https://github.com/UmerFruit/Hate_Explain.git\n",
        "%cd Hate_Explain\n",
        "print(\"DONE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EGDu9Wbvnm2",
        "outputId": "26a03a0d-299b-4dd5-ce9f-dc4a4e43cbec"
      },
      "id": "7EGDu9Wbvnm2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'Hate_Explain' already exists and is not an empty directory.\n",
            "/content/Hate_Explain\n",
            "DONE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a557a518",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a557a518",
        "outputId": "623c20a6-13cd-45a4-bd96-f73501f4f5e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPU Available: True\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# LOAD THE SMALL DATASET (GIVES KEY ERRORS SINCE IT DOESNT HAVE THE MOST OF THE WORDS)\n",
        "# !cp /content/drive/MyDrive/glove.42B.300d.small.zip ./Data/\n",
        "# Extract the zip file\n",
        "# !unzip -q ./Data/glove.42B.300d.small.zip -d ./Data/\n",
        "# !mv ./Data/glove.42B.300d.small.txt  ./Data/glove.42B.300d.txt\n",
        "\n",
        "# LOAD THE FULL DATASET\n",
        "print(\"Starting copy\")\n",
        "!cp /content/drive/MyDrive/glove.42B.300d.zip ./Data/\n",
        "# Extract the zip file\n",
        "print(\"Starting extraction\")\n",
        "!unzip -q ./Data/glove.42B.300d.zip -d ./Data/\n",
        "print(\"Done extraction\")\n",
        "\n",
        "# Clean up zip file (if needed)\n",
        "# !rm ./Data/glove.42B.300d.small.zip\n",
        "# !rm ./Data/glove.42B.300d.zip\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"\\nGPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b64eb58",
      "metadata": {
        "id": "7b64eb58"
      },
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c630f3f1",
      "metadata": {
        "id": "c630f3f1"
      },
      "outputs": [],
      "source": [
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ed11d7bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed11d7bc",
        "outputId": "7589f9bd-3353-4d45-9764-d716d1a3adae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create necessary directories\n",
        "import os\n",
        "os.makedirs('Saved', exist_ok=True)\n",
        "os.makedirs('explanations_dicts', exist_ok=True)\n",
        "print(\"Directories created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e725d768",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e725d768",
        "outputId": "1ee6dbac-08c5-4ed1-c1a1-221e03829963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (4.57.2)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: spacy>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (3.8.11)\n",
            "Requirement already satisfied: gensim>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (4.4.0)\n",
            "Requirement already satisfied: ekphrasis>=0.5.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.5.4)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (4.67.1)\n",
            "Requirement already satisfied: lime>=0.2.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (0.2.0.1)\n",
            "Requirement already satisfied: GPUtil>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (10.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 7)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (0.20.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (2.12.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim>=4.3.0->-r requirements.txt (line 11)) (7.5.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from ekphrasis>=0.5.4->-r requirements.txt (line 12)) (3.2.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from ekphrasis>=0.5.4->-r requirements.txt (line 12)) (0.4.6)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.12/dist-packages (from ekphrasis>=0.5.4->-r requirements.txt (line 12)) (5.11.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from ekphrasis>=0.5.4->-r requirements.txt (line 12)) (3.9.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from ekphrasis>=0.5.4->-r requirements.txt (line 12)) (6.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 15)) (3.2.5)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime>=0.2.0.1->-r requirements.txt (line 19)) (0.25.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.36.0->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.7.0->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.7.0->-r requirements.txt (line 10)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.7.0->-r requirements.txt (line 10)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 3)) (2025.11.12)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime>=0.2.0.1->-r requirements.txt (line 19)) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime>=0.2.0.1->-r requirements.txt (line 19)) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime>=0.2.0.1->-r requirements.txt (line 19)) (0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim>=4.3.0->-r requirements.txt (line 11)) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.7.0->-r requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.7.0->-r requirements.txt (line 10)) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=3.7.0->-r requirements.txt (line 10)) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.7.0->-r requirements.txt (line 10)) (0.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->ekphrasis>=0.5.4->-r requirements.txt (line 12)) (0.2.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 2)) (3.0.3)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# Install required packages (run this if not already installed)\n",
        "!pip install -r requirements.txt\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "931f2403",
      "metadata": {
        "id": "931f2403"
      },
      "source": [
        "## 2. Download and Prepare GloVe Embeddings\n",
        "\n",
        "**Note:** This step is only required once. Skip if you already have the file. Like i did with in the google drive mounted. If not it downloads it right here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ca9c64cf",
      "metadata": {
        "id": "ca9c64cf"
      },
      "outputs": [],
      "source": [
        "# Download GloVe embeddings (only run if needed)\n",
        "# !wget http://nlp.stanford.edu/data/glove.42B.300d.zip -P Data/\n",
        "# !unzip Data/glove.42B.300d.zip -d Data/\n",
        "# !rm Data/glove.42B.300d.zip\n",
        "# print(\"GloVe embeddings downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "044d03bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "044d03bc",
        "outputId": "44300541-172f-4720-9d97-e76120ec8725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting GloVe to Word2Vec format...\n",
            "Loading and saving model (this may take a few minutes)...\n",
            "Done! word2vec.model saved.\n"
          ]
        }
      ],
      "source": [
        "# Convert GloVe to Word2Vec format (REQUIRED for Colab - run this!)\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "# Convert GloVe format to Word2Vec format\n",
        "print(\"Converting GloVe to Word2Vec format...\")\n",
        "glove2word2vec('Data/glove.42B.300d.txt', 'Data/glove.42B.300d_w2v.txt')\n",
        "\n",
        "# Load and save in gensim format\n",
        "print(\"Loading and saving model (this may take a few minutes)...\")\n",
        "word2vecmodel1 = KeyedVectors.load_word2vec_format('Data/glove.42B.300d_w2v.txt', binary=False)\n",
        "word2vecmodel1.save(\"Data/word2vec.model\")\n",
        "\n",
        "# Clean up intermediate files\n",
        "import gc\n",
        "del word2vecmodel1\n",
        "gc.collect()\n",
        "\n",
        "# Remove large text files to save space\n",
        "import os\n",
        "os.remove('Data/glove.42B.300d.txt')\n",
        "os.remove('Data/glove.42B.300d_w2v.txt')\n",
        "print(\"Done! word2vec.model saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7938582a",
      "metadata": {
        "id": "7938582a"
      },
      "source": [
        "## 3. Import Dependencies and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7ff1eed7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ff1eed7",
        "outputId": "6099b817-6763-450b-fe3d-231ca1e71b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "Reading english - 1grams ...\n"
          ]
        }
      ],
      "source": [
        "# Import the training module\n",
        "from manual_training_inference import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e9079f11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9079f11",
        "outputId": "b337ccf3-bb48-4386-a050-49509c577a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Load model parameters from JSON configuration\n",
        "import json\n",
        "import ast\n",
        "import torch\n",
        "\n",
        "path_file = 'best_model_json/bestModel_birnnscrat.json'\n",
        "with open(path_file, mode='r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "# Convert string values to appropriate types\n",
        "for key in params:\n",
        "    if params[key] == 'True':\n",
        "        params[key] = True\n",
        "    elif params[key] == 'False':\n",
        "        params[key] = False\n",
        "    if key in ['batch_size', 'num_classes', 'hidden_size', 'supervised_layer_pos',\n",
        "               'num_supervised_heads', 'random_seed', 'max_length']:\n",
        "        if params[key] != 'N/A':\n",
        "            params[key] = int(params[key])\n",
        "    if (key == 'weights') and (params['auto_weights'] == False):\n",
        "        params[key] = ast.literal_eval(params[key])\n",
        "\n",
        "# Configure for Colab execution\n",
        "params['logging'] = 'local'\n",
        "params['device'] = 'cuda'  # Use GPU in Colab\n",
        "params['best_params'] = False\n",
        "\n",
        "# Setup device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'Using GPU: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    print('WARNING: GPU not available. Using CPU (training will be slow).')\n",
        "    print('Go to Runtime → Change runtime type → GPU')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "01d7f249",
      "metadata": {
        "id": "01d7f249"
      },
      "outputs": [],
      "source": [
        "# Data folder configuration\n",
        "dict_data_folder = {\n",
        "    '2': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes_two.npy'},\n",
        "    '3': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes.npy'}\n",
        "}\n",
        "\n",
        "# Configure training parameters\n",
        "params['variance'] = 1\n",
        "params['epochs'] = 5  # Reduce for faster testing\n",
        "params['to_save'] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0d1e4a47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d1e4a47",
        "outputId": "8e30216d-8d55-4d18-e3fa-6e0b8ba8923d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 2-class model...\n",
            "total_data 20148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20148/20148 [00:28<00:00, 707.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_error: 0\n",
            "no_majority: 919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 2643/15383 [00:00<00:00, 13460.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15383/15383 [00:01<00:00, 14348.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22236, 300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15383/15383 [00:00<00:00, 22871.73it/s]\n",
            "100%|██████████| 1922/1922 [00:00<00:00, 22402.32it/s]\n",
            "100%|██████████| 1924/1924 [00:00<00:00, 21572.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total dataset size: 19229\n",
            "[1.2301791 0.8423818]\n",
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:20, 24.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.3082358505027\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 578.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.63\n",
            " Fscore: 0.62\n",
            " Precision: 0.73\n",
            " Recall: 0.68\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 491.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.59\n",
            " Precision: 0.71\n",
            " Recall: 0.66\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 588.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.62\n",
            " Fscore: 0.61\n",
            " Precision: 0.72\n",
            " Recall: 0.67\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6054, accuracy: 0.6154\n",
            "  Val  - fscore: 0.5921, accuracy: 0.6041\n",
            "  Train- fscore: 0.6216, accuracy: 0.6300\n",
            "0.592106514423526 0\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.18436814147566\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 568.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.69\n",
            " Fscore: 0.69\n",
            " Precision: 0.76\n",
            " Recall: 0.73\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 610.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.64\n",
            " Fscore: 0.64\n",
            " Precision: 0.72\n",
            " Recall: 0.69\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 605.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.66\n",
            " Fscore: 0.65\n",
            " Precision: 0.73\n",
            " Recall: 0.70\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6510, accuracy: 0.6554\n",
            "  Val  - fscore: 0.6350, accuracy: 0.6400\n",
            "  Train- fscore: 0.6905, accuracy: 0.6928\n",
            "0.6350006641221457 0.592106514423526\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.09495852147217\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 558.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.82\n",
            " Fscore: 0.82\n",
            " Precision: 0.82\n",
            " Recall: 0.83\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 583.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.71\n",
            " Fscore: 0.71\n",
            " Precision: 0.73\n",
            " Recall: 0.73\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 590.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.72\n",
            " Fscore: 0.72\n",
            " Precision: 0.74\n",
            " Recall: 0.74\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.7221, accuracy: 0.7225\n",
            "  Val  - fscore: 0.7100, accuracy: 0.7102\n",
            "  Train- fscore: 0.8154, accuracy: 0.8164\n",
            "0.7100243101405113 0.6350006641221457\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.02775043955467\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 570.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.85\n",
            " Fscore: 0.85\n",
            " Precision: 0.85\n",
            " Recall: 0.86\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 581.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.71\n",
            " Fscore: 0.71\n",
            " Precision: 0.72\n",
            " Recall: 0.72\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 602.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.71\n",
            " Fscore: 0.71\n",
            " Precision: 0.72\n",
            " Recall: 0.73\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.7119, accuracy: 0.7131\n",
            "  Val  - fscore: 0.7086, accuracy: 0.7097\n",
            "  Train- fscore: 0.8507, accuracy: 0.8525\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 294.98696398189804\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 559.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.70\n",
            " Fscore: 0.70\n",
            " Precision: 0.78\n",
            " Recall: 0.75\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 581.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.59\n",
            " Fscore: 0.58\n",
            " Precision: 0.70\n",
            " Recall: 0.65\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 562.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.59\n",
            " Precision: 0.71\n",
            " Recall: 0.66\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.5895, accuracy: 0.6014\n",
            "  Val  - fscore: 0.5800, accuracy: 0.5926\n",
            "  Train- fscore: 0.7022, accuracy: 0.7050\n",
            "best_val_fscore 0.7100243101405113\n",
            "best_test_fscore 0.7220853499008352\n",
            "best_val_rocauc 0\n",
            "best_test_rocauc 0\n",
            "best_val_precision 0.7275168022326436\n",
            "best_test_precision 0.736239576764067\n",
            "best_val_recall 0.7312727452276402\n",
            "best_test_recall 0.7416095959437609\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Train with 2 classes (toxic vs non-toxic)\n",
        "params['num_classes'] = 2\n",
        "params['data_file'] = dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names'] = dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "if params['num_classes'] == 2 and params['auto_weights'] == False:\n",
        "    params['weights'] = [1.0, 1.0]\n",
        "\n",
        "print(f\"Training {params['num_classes']}-class model...\")\n",
        "train_model(params, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cf0fc73b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf0fc73b",
        "outputId": "ad9d580e-8c18-427d-9268-377acffa473d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 3-class model...\n",
            "total_data 20148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20148/20148 [00:26<00:00, 748.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_error: 0\n",
            "no_majority: 919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 2511/15383 [00:00<00:01, 12720.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15383/15383 [00:01<00:00, 13780.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22236, 300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15383/15383 [00:00<00:00, 22647.87it/s]\n",
            "100%|██████████| 1922/1922 [00:00<00:00, 22016.62it/s]\n",
            "100%|██████████| 1924/1924 [00:00<00:00, 22430.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total dataset size: 19229\n",
            "[1.0796857 0.8201194 1.1703163]\n",
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.68468743401604\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 562.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.61\n",
            " Fscore: 0.58\n",
            " Precision: 0.63\n",
            " Recall: 0.58\n",
            " Roc Auc: 0.79\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 519.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.56\n",
            " Precision: 0.63\n",
            " Recall: 0.56\n",
            " Roc Auc: 0.77\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 621.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.59\n",
            " Fscore: 0.55\n",
            " Precision: 0.62\n",
            " Recall: 0.55\n",
            " Roc Auc: 0.77\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.5524, accuracy: 0.5878\n",
            "  Val  - fscore: 0.5617, accuracy: 0.5963\n",
            "  Train- fscore: 0.5782, accuracy: 0.6105\n",
            "0.5616702167867701 0\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 42.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.5435634938198\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 562.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.69\n",
            " Fscore: 0.67\n",
            " Precision: 0.69\n",
            " Recall: 0.67\n",
            " Roc Auc: 0.84\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 616.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.62\n",
            " Fscore: 0.60\n",
            " Precision: 0.62\n",
            " Recall: 0.60\n",
            " Roc Auc: 0.79\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 611.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.64\n",
            " Fscore: 0.61\n",
            " Precision: 0.64\n",
            " Recall: 0.61\n",
            " Roc Auc: 0.79\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6150, accuracy: 0.6362\n",
            "  Val  - fscore: 0.5992, accuracy: 0.6223\n",
            "  Train- fscore: 0.6704, accuracy: 0.6873\n",
            "0.5992262854884399 0.5616702167867701\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.4403857193469\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 554.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.74\n",
            " Fscore: 0.73\n",
            " Precision: 0.74\n",
            " Recall: 0.73\n",
            " Roc Auc: 0.89\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 583.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.63\n",
            " Precision: 0.65\n",
            " Recall: 0.63\n",
            " Roc Auc: 0.81\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 605.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.63\n",
            " Precision: 0.65\n",
            " Recall: 0.63\n",
            " Roc Auc: 0.81\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6304, accuracy: 0.6492\n",
            "  Val  - fscore: 0.6292, accuracy: 0.6483\n",
            "  Train- fscore: 0.7318, accuracy: 0.7435\n",
            "0.6292216536100552 0.5992262854884399\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.37425653850215\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 562.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.78\n",
            " Fscore: 0.78\n",
            " Precision: 0.78\n",
            " Recall: 0.77\n",
            " Roc Auc: 0.92\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 552.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.64\n",
            " Precision: 0.65\n",
            " Recall: 0.63\n",
            " Roc Auc: 0.81\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 604.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.64\n",
            " Fscore: 0.63\n",
            " Precision: 0.64\n",
            " Recall: 0.63\n",
            " Roc Auc: 0.80\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.6332, accuracy: 0.6435\n",
            "  Val  - fscore: 0.6400, accuracy: 0.6504\n",
            "  Train- fscore: 0.7758, accuracy: 0.7817\n",
            "0.639963820145986 0.6292216536100552\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:11, 41.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_train_loss 295.3143782585921\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "481it [00:00, 554.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.76\n",
            " Fscore: 0.75\n",
            " Precision: 0.78\n",
            " Recall: 0.74\n",
            " Roc Auc: 0.92\n",
            " Test took: 0:00:01\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 545.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.57\n",
            " Precision: 0.62\n",
            " Recall: 0.57\n",
            " Roc Auc: 0.77\n",
            " Test took: 0:00:00\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "61it [00:00, 584.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.57\n",
            " Precision: 0.62\n",
            " Recall: 0.56\n",
            " Roc Auc: 0.76\n",
            " Test took: 0:00:00\n",
            "  Test - fscore: 0.5673, accuracy: 0.5951\n",
            "  Val  - fscore: 0.5701, accuracy: 0.5968\n",
            "  Train- fscore: 0.7524, accuracy: 0.7645\n",
            "best_val_fscore 0.639963820145986\n",
            "best_test_fscore 0.6332487108352621\n",
            "best_val_rocauc 0.8071006833165059\n",
            "best_test_rocauc 0.8039198584224749\n",
            "best_val_precision 0.6517608919125689\n",
            "best_test_precision 0.6419289825978067\n",
            "best_val_recall 0.6348165172902596\n",
            "best_test_recall 0.6290887648657669\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Train with 3 classes (hatespeech, offensive, normal)\n",
        "params['num_classes'] = 3\n",
        "params['data_file'] = dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names'] = dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "if params['num_classes'] == 2 and params['auto_weights'] == False:\n",
        "    params['weights'] = [1.0, 1.0]\n",
        "\n",
        "print(f\"Training {params['num_classes']}-class model...\")\n",
        "train_model(params, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d53f6556",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d53f6556",
        "outputId": "836700cb-0569-436b-8757-dd922229f4b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Clean up memory\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6620763",
      "metadata": {
        "id": "a6620763"
      },
      "source": [
        "## 4. Testing and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7119f203",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7119f203",
        "outputId": "45ec1d82-11fa-4405-8d2e-0079e21cf58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-06 18:32:10.997671: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765045931.027185   12920 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765045931.039067   12920 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765045931.073329   12920 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765045931.073361   12920 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765045931.073365   12920 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765045931.073370   12920 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n",
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n",
            "Reading english - 1grams ...\n",
            "Since you dont want to use GPU, using the CPU instead.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Hate_Explain/testing_with_rational.py\", line 340, in <module>\n",
            "    final_list_dict=get_final_dict_with_rational(params, params['data_file'],topk=5)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Hate_Explain/testing_with_rational.py\", line 273, in get_final_dict_with_rational\n",
            "    list_dict_org,test_data=standaloneEval_with_rational(params, extra_data_path=test_data,topk=topk)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Hate_Explain/testing_with_rational.py\", line 120, in standaloneEval_with_rational\n",
            "    params['weights']=class_weight.compute_class_weight('balanced',np.unique(y_test),y_test).astype('float32')\n",
            "                      ^^^^^^^^^^^^\n",
            "NameError: name 'class_weight' is not defined\n",
            "\u001b[0m2025-12-06 18:32:52.785643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765045972.812828   13110 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765045972.823192   13110 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765045972.852002   13110 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765045972.852029   13110 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765045972.852035   13110 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765045972.852039   13110 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n",
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "/usr/local/lib/python3.12/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n",
            "Reading english - 1grams ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Hate_Explain/testing_for_bias.py\", line 282, in <module>\n",
            "    final_dict=get_final_dict(params, params['data_file'],topk=5)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Hate_Explain/testing_for_bias.py\", line 214, in get_final_dict\n",
            "    list_dict_org,test_data=standaloneEval(params, extra_data_path=test_data, topk=2)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Hate_Explain/testing_for_bias.py\", line 110, in standaloneEval\n",
            "    params['weights']=class_weight.compute_class_weight('balanced',np.unique(y_test),y_test).astype('float32')\n",
            "                      ^^^^^^^^^^^^\n",
            "NameError: name 'class_weight' is not defined\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Run testing scripts\n",
        "!python testing_with_rational.py birnn_scrat 100\n",
        "!python testing_for_bias.py birnn_scrat 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9fb37bfd",
      "metadata": {
        "id": "9fb37bfd"
      },
      "outputs": [],
      "source": [
        "# Check generated explanation files\n",
        "!ls explanations_dicts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e805472e",
      "metadata": {
        "id": "e805472e"
      },
      "source": [
        "---\n",
        "\n",
        "# Bias Calculation\n",
        "\n",
        "Based on: Borkan et al. (2019) - \"Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification\"\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cd70e916",
      "metadata": {
        "id": "cd70e916"
      },
      "outputs": [],
      "source": [
        "# Import required libraries for bias calculation\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ae89aa08",
      "metadata": {
        "id": "ae89aa08"
      },
      "outputs": [],
      "source": [
        "# Import data collection utilities\n",
        "from Preprocess.dataCollect import get_annotated_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7b7497b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b7497b6",
        "outputId": "49cc406a-7212-40cb-d9b9-60712bebf005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 20148 samples\n"
          ]
        }
      ],
      "source": [
        "# Configure data loading for 2-class (toxic/non-toxic)\n",
        "dict_data_folder = {\n",
        "    '2': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes_two.npy'},\n",
        "    '3': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes.npy'}\n",
        "}\n",
        "\n",
        "params = {}\n",
        "params['num_classes'] = 2  # toxic vs non-toxic\n",
        "params['data_file'] = dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names'] = dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "# Load the annotated dataset\n",
        "data_all_labelled = get_annotated_data(params)\n",
        "print(f\"Loaded {len(data_all_labelled)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c9ddf105",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "c9ddf105",
        "outputId": "017fc43a-1a8f-42c6-8cbc-bbbccb41eceb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       post_id  \\\n",
              "0  1179055004553900032_twitter   \n",
              "1  1179063826874032128_twitter   \n",
              "2  1178793830532956161_twitter   \n",
              "3  1179088797964763136_twitter   \n",
              "4  1179085312976445440_twitter   \n",
              "\n",
              "                                                text  annotatorid1  \\\n",
              "0  [i, dont, think, im, getting, my, baby, them, ...             1   \n",
              "1  [we, cannot, continue, calling, ourselves, fem...             1   \n",
              "2                [nawt, yall, niggers, ignoring, me]             4   \n",
              "3  [<user>, i, am, bit, confused, coz, chinese, p...             1   \n",
              "4  [this, bitch, in, whataburger, eating, a, burg...             4   \n",
              "\n",
              "              target1      label1  annotatorid2             target2  \\\n",
              "0              [None]      normal             2              [None]   \n",
              "1              [None]      normal             2              [None]   \n",
              "2           [African]      normal             2              [None]   \n",
              "3             [Asian]  hatespeech             4             [Asian]   \n",
              "4  [Caucasian, Women]  hatespeech             2  [Women, Caucasian]   \n",
              "\n",
              "       label2  annotatorid3             target3      label3  \\\n",
              "0      normal             3              [None]      normal   \n",
              "1      normal             3              [None]      normal   \n",
              "2      normal             3           [African]  hatespeech   \n",
              "3   offensive             3             [Asian]  hatespeech   \n",
              "4  hatespeech             3  [Women, Caucasian]   offensive   \n",
              "\n",
              "                                          rationales final_label  \n",
              "0                                                 []   non-toxic  \n",
              "1                                                 []   non-toxic  \n",
              "2                                                 []   non-toxic  \n",
              "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...       toxic  \n",
              "4  [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...       toxic  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8a682a0-60b6-4140-bf93-3aa81246f0b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>text</th>\n",
              "      <th>annotatorid1</th>\n",
              "      <th>target1</th>\n",
              "      <th>label1</th>\n",
              "      <th>annotatorid2</th>\n",
              "      <th>target2</th>\n",
              "      <th>label2</th>\n",
              "      <th>annotatorid3</th>\n",
              "      <th>target3</th>\n",
              "      <th>label3</th>\n",
              "      <th>rationales</th>\n",
              "      <th>final_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1179055004553900032_twitter</td>\n",
              "      <td>[i, dont, think, im, getting, my, baby, them, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1179063826874032128_twitter</td>\n",
              "      <td>[we, cannot, continue, calling, ourselves, fem...</td>\n",
              "      <td>1</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1178793830532956161_twitter</td>\n",
              "      <td>[nawt, yall, niggers, ignoring, me]</td>\n",
              "      <td>4</td>\n",
              "      <td>[African]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[African]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1179088797964763136_twitter</td>\n",
              "      <td>[&lt;user&gt;, i, am, bit, confused, coz, chinese, p...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>4</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>3</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1179085312976445440_twitter</td>\n",
              "      <td>[this, bitch, in, whataburger, eating, a, burg...</td>\n",
              "      <td>4</td>\n",
              "      <td>[Caucasian, Women]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>2</td>\n",
              "      <td>[Women, Caucasian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>3</td>\n",
              "      <td>[Women, Caucasian]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8a682a0-60b6-4140-bf93-3aa81246f0b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8a682a0-60b6-4140-bf93-3aa81246f0b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8a682a0-60b6-4140-bf93-3aa81246f0b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-857be5af-5463-4f8a-9f36-bfc623b7e043\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-857be5af-5463-4f8a-9f36-bfc623b7e043')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-857be5af-5463-4f8a-9f36-bfc623b7e043 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_all_labelled",
              "summary": "{\n  \"name\": \"data_all_labelled\",\n  \"rows\": 20148,\n  \"fields\": [\n    {\n      \"column\": \"post_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20148,\n        \"samples\": [\n          \"21376810_gab\",\n          \"1080843707643944965_twitter\",\n          \"1178183797461811200_twitter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotatorid1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 95,\n        \"min\": 1,\n        \"max\": 251,\n        \"num_unique_values\": 194,\n        \"samples\": [\n          165,\n          41,\n          215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target1\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"normal\",\n          \"hatespeech\",\n          \"offensive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotatorid2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96,\n        \"min\": 1,\n        \"max\": 253,\n        \"num_unique_values\": 197,\n        \"samples\": [\n          173,\n          140,\n          37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target2\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"normal\",\n          \"offensive\",\n          \"hatespeech\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotatorid3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96,\n        \"min\": 1,\n        \"max\": 252,\n        \"num_unique_values\": 198,\n        \"samples\": [\n          96,\n          125,\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target3\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"normal\",\n          \"hatespeech\",\n          \"offensive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rationales\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"non-toxic\",\n          \"toxic\",\n          \"undecided\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Display sample data\n",
        "data_all_labelled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dc0b0a9f",
      "metadata": {
        "id": "dc0b0a9f"
      },
      "outputs": [],
      "source": [
        "def generate_target_information(dataset):\n",
        "    \"\"\"Extract target community based on majority voting among annotators.\"\"\"\n",
        "    final_target_output = defaultdict(list)\n",
        "    all_communities_selected = []\n",
        "\n",
        "    for each in dataset.iterrows():\n",
        "        # Combine all target communities from 3 annotators\n",
        "        all_targets = each[1]['target1'] + each[1]['target2'] + each[1]['target3']\n",
        "        community_dict = dict(Counter(all_targets))\n",
        "\n",
        "        # Select communities mentioned by at least 2 annotators\n",
        "        for key in community_dict:\n",
        "            if community_dict[key] > 1:\n",
        "                final_target_output[each[1]['post_id']].append(key)\n",
        "                all_communities_selected.append(key)\n",
        "\n",
        "        # If no majority, mark as 'None'\n",
        "        if each[1]['post_id'] not in final_target_output:\n",
        "            final_target_output[each[1]['post_id']].append('None')\n",
        "            all_communities_selected.append('None')\n",
        "\n",
        "    return final_target_output, all_communities_selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "810386dc",
      "metadata": {
        "id": "810386dc"
      },
      "outputs": [],
      "source": [
        "# Generate target information\n",
        "target_information, all_communities_selected = generate_target_information(data_all_labelled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "589a7c28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "589a7c28",
        "outputId": "6cd08d08-c982-4934-b08d-c91341149a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 communities: ['African', 'Islam', 'Jewish', 'Homosexual', 'Women', 'Refugee', 'Arab', 'Caucasian', 'Asian', 'Hispanic']\n"
          ]
        }
      ],
      "source": [
        "# Get top 10 communities for bias calculation\n",
        "community_count_dict = Counter(all_communities_selected)\n",
        "\n",
        "# Remove 'None' and 'Other' from consideration\n",
        "community_count_dict.pop('None', None)\n",
        "community_count_dict.pop('Other', None)\n",
        "\n",
        "# Select top 10 communities\n",
        "list_selected_community = [community for community, value in community_count_dict.most_common(10)]\n",
        "print(f\"Top 10 communities: {list_selected_community}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "02c85f4a",
      "metadata": {
        "id": "02c85f4a"
      },
      "outputs": [],
      "source": [
        "# Filter target information to only include top 10 communities\n",
        "final_target_information = {}\n",
        "for each in target_information:\n",
        "    temp = list(set(target_information[each]) & set(list_selected_community))\n",
        "    if len(temp) == 0:\n",
        "        final_target_information[each] = None\n",
        "    else:\n",
        "        final_target_information[each] = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d537ba3a",
      "metadata": {
        "id": "d537ba3a"
      },
      "outputs": [],
      "source": [
        "# Add target category column to dataset\n",
        "data_all_labelled['final_target_category'] = data_all_labelled['post_id'].map(final_target_information)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7dd8cd32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dd8cd32",
        "outputId": "fecb15f3-09b6-4d37-e795-6a10bb5c2356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test samples for bias evaluation: 1924\n"
          ]
        }
      ],
      "source": [
        "# Load test split IDs and filter data\n",
        "with open('./Data/post_id_divisions.json', 'r') as fp:\n",
        "    post_id_dict = json.load(fp)\n",
        "\n",
        "data_all_labelled_bias = data_all_labelled[data_all_labelled['post_id'].isin(post_id_dict['test'])]\n",
        "print(f\"Test samples for bias evaluation: {len(data_all_labelled_bias)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "14ae2de9",
      "metadata": {
        "id": "14ae2de9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Bias score file mapping for the trained model\n",
        "bias_score_file_mapping = {\n",
        "    'BiRNN-Attn': 'bestModel_birnnscrat_bias.json',\n",
        "}\n",
        "\n",
        "parent_path = './explanations_dicts/'\n",
        "method_list = ['subgroup', 'bpsn', 'bnsp']\n",
        "community_list = list(list_selected_community)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "757024c0",
      "metadata": {
        "id": "757024c0"
      },
      "outputs": [],
      "source": [
        "def convert_to_score(label_name, label_dict):\n",
        "    \"\"\"Convert classification to toxicity score [0-1].\"\"\"\n",
        "    if label_name == 'non-toxic':\n",
        "        return 1 - label_dict[label_name]\n",
        "    else:\n",
        "        return label_dict[label_name]\n",
        "\n",
        "\n",
        "def bias_evaluation_metric(dataset, method, community):\n",
        "    \"\"\"Divide IDs into positive/negative based on bias evaluation method.\"\"\"\n",
        "    positive_ids = []\n",
        "    negative_ids = []\n",
        "\n",
        "    for eachrow in dataset.iterrows():\n",
        "        if eachrow[1]['final_target_category'] is None:\n",
        "            continue\n",
        "\n",
        "        is_community = community in eachrow[1]['final_target_category']\n",
        "        is_toxic = eachrow[1]['final_label'] != 'non-toxic'\n",
        "\n",
        "        if method == 'subgroup':\n",
        "            if is_community:\n",
        "                if is_toxic:\n",
        "                    positive_ids.append(eachrow[1]['post_id'])\n",
        "                else:\n",
        "                    negative_ids.append(eachrow[1]['post_id'])\n",
        "        elif method == 'bpsn':\n",
        "            if is_community and not is_toxic:\n",
        "                negative_ids.append(eachrow[1]['post_id'])\n",
        "            elif not is_community and is_toxic:\n",
        "                positive_ids.append(eachrow[1]['post_id'])\n",
        "        elif method == 'bnsp':\n",
        "            if is_community and is_toxic:\n",
        "                positive_ids.append(eachrow[1]['post_id'])\n",
        "            elif not is_community and not is_toxic:\n",
        "                negative_ids.append(eachrow[1]['post_id'])\n",
        "        else:\n",
        "            print('Incorrect method selected!')\n",
        "\n",
        "    return {'positiveID': positive_ids, 'negativeID': negative_ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "41dd1847",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0dd868278f3a4310944838b3aa6e60d2",
            "3a6e487104d448278a8a0d274d065ed7",
            "f57817af75db4888a428c95205524755",
            "0deed6fee9b3445ea5665430684e310d",
            "2221f92a6543410a8c422727565ccc6d",
            "a3d3c44b373b4c11a45973f13982b3d0",
            "d2ede3832d2b4a62ab35f3627ddb034f",
            "d3a3a000c742405db80e4e645a3cb9a9",
            "7bb2e655602648e0943850afc26e606e",
            "5b6622c991e948da95c47b60a3563889",
            "f0edbe89bf1740a0be4355550308aad7"
          ]
        },
        "id": "41dd1847",
        "outputId": "58f8e660-5dac-448f-f787-4bcec88c3c6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing models:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dd868278f3a4310944838b3aa6e60d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: ./explanations_dicts/bestModel_birnnscrat_bias.json not found. Run testing scripts first.\n"
          ]
        }
      ],
      "source": [
        "# Calculate bias scores\n",
        "final_bias_dictionary = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "for each_model in tqdm(bias_score_file_mapping, desc=\"Processing models\"):\n",
        "    total_data = {}\n",
        "    filepath = parent_path + bias_score_file_mapping[each_model]\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Warning: {filepath} not found. Run testing scripts first.\")\n",
        "        continue\n",
        "\n",
        "    with open(filepath) as fp:\n",
        "        for line in fp:\n",
        "            data = json.loads(line)\n",
        "            total_data[data['annotation_id']] = data\n",
        "\n",
        "    for each_method in method_list:\n",
        "        for each_community in community_list:\n",
        "            community_data = bias_evaluation_metric(data_all_labelled_bias, each_method, each_community)\n",
        "            truth_values = []\n",
        "            prediction_values = []\n",
        "\n",
        "            label_to_value = {'toxic': 1.0, 'non-toxic': 0.0}\n",
        "\n",
        "            for each in community_data['positiveID']:\n",
        "                if each in total_data:\n",
        "                    truth_values.append(label_to_value[total_data[each]['ground_truth']])\n",
        "                    prediction_values.append(convert_to_score(\n",
        "                        total_data[each]['classification'],\n",
        "                        total_data[each]['classification_scores']\n",
        "                    ))\n",
        "\n",
        "            for each in community_data['negativeID']:\n",
        "                if each in total_data:\n",
        "                    truth_values.append(label_to_value[total_data[each]['ground_truth']])\n",
        "                    prediction_values.append(convert_to_score(\n",
        "                        total_data[each]['classification'],\n",
        "                        total_data[each]['classification_scores']\n",
        "                    ))\n",
        "\n",
        "            if len(truth_values) > 0 and len(set(truth_values)) > 1:\n",
        "                roc_output_value = roc_auc_score(truth_values, prediction_values)\n",
        "                final_bias_dictionary[each_model][each_method][each_community] = roc_output_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e2000d34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2000d34",
        "outputId": "0889429a-b0f3-4d33-b1be-9b9840c57da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bias Scores (Generalized Mean):\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Calculate generalized mean of bias scores\n",
        "power_value = -5\n",
        "num_communities = len(community_list)\n",
        "\n",
        "print(\"\\nBias Scores (Generalized Mean):\")\n",
        "print(\"=\" * 50)\n",
        "for each_model in final_bias_dictionary:\n",
        "    for each_method in final_bias_dictionary[each_model]:\n",
        "        temp_value = []\n",
        "        for each_community in final_bias_dictionary[each_model][each_method]:\n",
        "            temp_value.append(pow(final_bias_dictionary[each_model][each_method][each_community], power_value))\n",
        "        if len(temp_value) > 0:\n",
        "            score = pow(np.sum(temp_value) / num_communities, 1 / power_value)\n",
        "            print(f\"{each_model} | {each_method}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ed22331",
      "metadata": {
        "id": "2ed22331"
      },
      "source": [
        "---\n",
        "\n",
        "# Calculate Explainability\n",
        "\n",
        "Based on: DeYoung et al. (2020) - \"ERASER: A Benchmark to Evaluate Rationalized NLP Models\"\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "88c76dd4",
      "metadata": {
        "id": "88c76dd4"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import more_itertools as mit\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9e9aa0c6",
      "metadata": {
        "id": "9e9aa0c6"
      },
      "outputs": [],
      "source": [
        "# Import preprocessing utilities\n",
        "from Preprocess.dataCollect import get_annotated_data\n",
        "from Preprocess.spanMatcher import returnMask\n",
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "57ef8972",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ef8972",
        "outputId": "e192ee27-0de6-401e-d043-23caf1e4848a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 20148 samples for explainability evaluation\n"
          ]
        }
      ],
      "source": [
        "# Load 3-class dataset for explainability\n",
        "dict_data_folder = {\n",
        "    '2': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes_two.npy'},\n",
        "    '3': {'data_file': 'Data/dataset.json', 'class_label': 'Data/classes.npy'}\n",
        "}\n",
        "\n",
        "params = {}\n",
        "params['num_classes'] = 3  # hatespeech, offensive, normal\n",
        "params['data_file'] = dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names'] = dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "data_all_labelled = get_annotated_data(params)\n",
        "print(f\"Loaded {len(data_all_labelled)} samples for explainability evaluation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "eddc527e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eddc527e",
        "outputId": "64c1e68e-b4e7-46ac-cc46-dede80738951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using standard tokenizer...\n"
          ]
        }
      ],
      "source": [
        "# Configure tokenization parameters\n",
        "params_data = {\n",
        "    'include_special': False,\n",
        "    'bert_tokens': False,  # Set True for BERT models\n",
        "    'type_attention': 'softmax',\n",
        "    'set_decay': 0.1,\n",
        "    'majority': 2,\n",
        "    'max_length': 128,\n",
        "    'variance': 10,\n",
        "    'window': 4,\n",
        "    'alpha': 0.5,\n",
        "    'p_value': 0.8,\n",
        "    'method': 'additive',\n",
        "    'decay': False,\n",
        "    'normalized': False,\n",
        "    'not_recollect': True,\n",
        "}\n",
        "\n",
        "# Initialize tokenizer\n",
        "if params_data['bert_tokens']:\n",
        "    print('Loading BERT tokenizer...')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=False)\n",
        "else:\n",
        "    print('Using standard tokenizer...')\n",
        "    tokenizer = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9ce975f4",
      "metadata": {
        "id": "9ce975f4"
      },
      "outputs": [],
      "source": [
        "def get_training_data(data):\n",
        "    \"\"\"Load dataset and extract token-wise rationales.\"\"\"\n",
        "    final_output = []\n",
        "    print(f'Processing {len(data)} samples...')\n",
        "\n",
        "    for index, row in tqdm(data.iterrows(), total=len(data)):\n",
        "        annotation = row['final_label']\n",
        "        post_id = row['post_id']\n",
        "        annotation_list = [row['label1'], row['label2'], row['label3']]\n",
        "\n",
        "        if annotation != 'undecided':\n",
        "            tokens_all, attention_masks = returnMask(row, params_data, tokenizer)\n",
        "            final_output.append([post_id, annotation, tokens_all, attention_masks, annotation_list])\n",
        "\n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "c18b4ce2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3a212d72aaa5425b9c7e0b219db54617",
            "ee08cc7d03d4444e91fa45134a167117",
            "6e53b52087354b2db50ae284b30eff62",
            "4bec223742e348fd9086eea5a03ef7bb",
            "9b4860c1bb84481fa3b9a252c6dd9b50",
            "a97f729f849f4f89adc8b64355d2e502",
            "fc093ff4dc624ec18b5e78153687eaa6",
            "ece0198d097e47079d6d5fcaa4a11518",
            "82a15b52d26643e2a8e6a1e2b3a15eac",
            "444e04d032354e7786d9f980b66c47a5",
            "1d4c1cd205b64470a7fc79d593776365"
          ]
        },
        "id": "c18b4ce2",
        "outputId": "b8240421-7ece-47e3-ca87-d7768e893067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 20148 samples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a212d72aaa5425b9c7e0b219db54617"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19229 valid samples\n"
          ]
        }
      ],
      "source": [
        "# Process training data\n",
        "training_data = get_training_data(data_all_labelled)\n",
        "print(f\"Processed {len(training_data)} valid samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "71bb9b84",
      "metadata": {
        "id": "71bb9b84"
      },
      "outputs": [],
      "source": [
        "def find_ranges(iterable):\n",
        "    \"\"\"Yield ranges of consecutive numbers.\"\"\"\n",
        "    for group in mit.consecutive_groups(iterable):\n",
        "        group = list(group)\n",
        "        if len(group) == 1:\n",
        "            yield group[0]\n",
        "        else:\n",
        "            yield group[0], group[-1]\n",
        "\n",
        "\n",
        "def get_evidence(post_id, anno_text, explanations):\n",
        "    \"\"\"Convert explanations to ERASER evidence format.\"\"\"\n",
        "    output = []\n",
        "    indexes = sorted([i for i, each in enumerate(explanations) if each == 1])\n",
        "    span_list = list(find_ranges(indexes))\n",
        "\n",
        "    for each in span_list:\n",
        "        if isinstance(each, int):\n",
        "            start, end = each, each + 1\n",
        "        elif len(each) == 2:\n",
        "            start, end = each[0], each[1] + 1\n",
        "        else:\n",
        "            print('Error in span processing')\n",
        "            continue\n",
        "\n",
        "        output.append({\n",
        "            \"docid\": post_id,\n",
        "            \"end_sentence\": -1,\n",
        "            \"end_token\": end,\n",
        "            \"start_sentence\": -1,\n",
        "            \"start_token\": start,\n",
        "            \"text\": ' '.join([str(x) for x in anno_text[start:end]])\n",
        "        })\n",
        "    return output\n",
        "\n",
        "\n",
        "def convert_to_eraser_format(dataset, method, save_split, save_path, id_division):\n",
        "    \"\"\"Convert dataset to ERASER benchmark format.\"\"\"\n",
        "    final_output = []\n",
        "\n",
        "    if save_split:\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        os.makedirs(os.path.join(save_path, 'docs'), exist_ok=True)\n",
        "        train_fp = open(os.path.join(save_path, 'train.jsonl'), 'w')\n",
        "        val_fp = open(os.path.join(save_path, 'val.jsonl'), 'w')\n",
        "        test_fp = open(os.path.join(save_path, 'test.jsonl'), 'w')\n",
        "\n",
        "    for eachrow in dataset:\n",
        "        post_id = eachrow[0]\n",
        "        post_class = eachrow[1]\n",
        "        anno_text_list = eachrow[2]\n",
        "\n",
        "        if post_class == 'normal':\n",
        "            continue\n",
        "\n",
        "        explanations = [list(each_explain) for each_explain in eachrow[3]]\n",
        "\n",
        "        # Union of explanations from all annotators\n",
        "        if method == 'union':\n",
        "            final_explanation = [int(any(each)) for each in zip(*explanations)]\n",
        "\n",
        "        temp = {\n",
        "            'annotation_id': post_id,\n",
        "            'classification': post_class,\n",
        "            'evidences': [get_evidence(post_id, list(anno_text_list), final_explanation)],\n",
        "            'query': \"What is the class?\",\n",
        "            'query_type': None\n",
        "        }\n",
        "        final_output.append(temp)\n",
        "\n",
        "        if save_split:\n",
        "            # Save document\n",
        "            with open(os.path.join(save_path, 'docs', post_id), 'w') as fp:\n",
        "                fp.write(' '.join([str(x) for x in list(anno_text_list)]))\n",
        "\n",
        "            # Save to appropriate split\n",
        "            if post_id in id_division['train']:\n",
        "                train_fp.write(json.dumps(temp) + '\\n')\n",
        "            elif post_id in id_division['val']:\n",
        "                val_fp.write(json.dumps(temp) + '\\n')\n",
        "            elif post_id in id_division['test']:\n",
        "                test_fp.write(json.dumps(temp) + '\\n')\n",
        "\n",
        "    if save_split:\n",
        "        train_fp.close()\n",
        "        val_fp.close()\n",
        "        test_fp.close()\n",
        "\n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0e8013a1",
      "metadata": {
        "id": "0e8013a1"
      },
      "outputs": [],
      "source": [
        "# Load data splits\n",
        "with open('./Data/post_id_divisions.json') as fp:\n",
        "    id_division = json.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "80332ce4",
      "metadata": {
        "id": "80332ce4"
      },
      "outputs": [],
      "source": [
        "# Create evaluation directory\n",
        "os.makedirs('./Data/Evaluation/Model_Eval', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5d0e7d11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d0e7d11",
        "outputId": "a4d98490-c43e-4d26-c8ac-be76b834668e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 11415 samples to ERASER format\n"
          ]
        }
      ],
      "source": [
        "# Convert to ERASER format\n",
        "method = 'union'\n",
        "save_split = True\n",
        "save_path = './Data/Evaluation/Model_Eval/'\n",
        "\n",
        "output_eraser = convert_to_eraser_format(training_data, method, save_split, save_path, id_division)\n",
        "print(f\"Converted {len(output_eraser)} samples to ERASER format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0b2f7035",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b2f7035",
        "outputId": "e7bac6f2-a397-4f15-f24c-6cda84bff5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "docs  test.jsonl  train.jsonl  val.jsonl\n"
          ]
        }
      ],
      "source": [
        "# List generated files\n",
        "!ls Data/Evaluation/Model_Eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c70dfea6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70dfea6",
        "outputId": "cd3e9bbf-84be-4f6a-9875-40bd202b7c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation file not found: ./explanations_dicts/bestModel_birnnscrat_100_explanation_top5.json\n",
            "Run testing_with_rational.py first.\n"
          ]
        }
      ],
      "source": [
        "# Run ERASER metrics\n",
        "explanation_file = './explanations_dicts/bestModel_birnnscrat_100_explanation_top5.json'\n",
        "if os.path.exists(explanation_file):\n",
        "    !cd eraserbenchmark && PYTHONPATH=./:$PYTHONPATH python rationale_benchmark/metrics.py \\\n",
        "        --split test \\\n",
        "        --data_dir ../Data/Evaluation/Model_Eval \\\n",
        "        --results ../explanations_dicts/bestModel_birnnscrat_100_explanation_top5.json \\\n",
        "        --score_file ../model_explain_output.json\n",
        "else:\n",
        "    print(f\"Explanation file not found: {explanation_file}\")\n",
        "    print(\"Run testing_with_rational.py first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e2923617",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2923617",
        "outputId": "94a4d8bf-68b8-4760-d08c-94efd40f994e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output file not found: ./model_explain_output.json\n"
          ]
        }
      ],
      "source": [
        "# Print explainability results\n",
        "output_file = './model_explain_output.json'\n",
        "if os.path.exists(output_file):\n",
        "    with open(output_file) as fp:\n",
        "        output_data = json.load(fp)\n",
        "\n",
        "    print('\\n' + '=' * 50)\n",
        "    print('EXPLAINABILITY RESULTS')\n",
        "    print('=' * 50)\n",
        "\n",
        "    print('\\nPlausibility:')\n",
        "    print(f\"  IOU F1:   {output_data['iou_scores'][0]['macro']['f1']:.4f}\")\n",
        "    print(f\"  Token F1: {output_data['token_prf']['instance_macro']['f1']:.4f}\")\n",
        "    print(f\"  AUPRC:    {output_data['token_soft_metrics']['auprc']:.4f}\")\n",
        "\n",
        "    print('\\nFaithfulness:')\n",
        "    print(f\"  Comprehensiveness: {output_data['classification_scores']['comprehensiveness']:.4f}\")\n",
        "    print(f\"  Sufficiency:       {output_data['classification_scores']['sufficiency']:.4f}\")\n",
        "else:\n",
        "    print(f\"Output file not found: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a912fa",
      "metadata": {
        "id": "98a912fa"
      },
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. **Model Training**: Training BiRNN-SCRAT model for hate speech detection\n",
        "2. **Bias Evaluation**: Computing subgroup, BPSN, and BNSP bias metrics\n",
        "3. **Explainability Evaluation**: Computing plausibility and faithfulness metrics\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0dd868278f3a4310944838b3aa6e60d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a6e487104d448278a8a0d274d065ed7",
              "IPY_MODEL_f57817af75db4888a428c95205524755",
              "IPY_MODEL_0deed6fee9b3445ea5665430684e310d"
            ],
            "layout": "IPY_MODEL_2221f92a6543410a8c422727565ccc6d"
          }
        },
        "3a6e487104d448278a8a0d274d065ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d3c44b373b4c11a45973f13982b3d0",
            "placeholder": "​",
            "style": "IPY_MODEL_d2ede3832d2b4a62ab35f3627ddb034f",
            "value": "Processing models: 100%"
          }
        },
        "f57817af75db4888a428c95205524755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3a3a000c742405db80e4e645a3cb9a9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bb2e655602648e0943850afc26e606e",
            "value": 1
          }
        },
        "0deed6fee9b3445ea5665430684e310d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b6622c991e948da95c47b60a3563889",
            "placeholder": "​",
            "style": "IPY_MODEL_f0edbe89bf1740a0be4355550308aad7",
            "value": " 1/1 [00:00&lt;00:00, 57.09it/s]"
          }
        },
        "2221f92a6543410a8c422727565ccc6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d3c44b373b4c11a45973f13982b3d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ede3832d2b4a62ab35f3627ddb034f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3a3a000c742405db80e4e645a3cb9a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bb2e655602648e0943850afc26e606e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b6622c991e948da95c47b60a3563889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0edbe89bf1740a0be4355550308aad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a212d72aaa5425b9c7e0b219db54617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee08cc7d03d4444e91fa45134a167117",
              "IPY_MODEL_6e53b52087354b2db50ae284b30eff62",
              "IPY_MODEL_4bec223742e348fd9086eea5a03ef7bb"
            ],
            "layout": "IPY_MODEL_9b4860c1bb84481fa3b9a252c6dd9b50"
          }
        },
        "ee08cc7d03d4444e91fa45134a167117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a97f729f849f4f89adc8b64355d2e502",
            "placeholder": "​",
            "style": "IPY_MODEL_fc093ff4dc624ec18b5e78153687eaa6",
            "value": "100%"
          }
        },
        "6e53b52087354b2db50ae284b30eff62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece0198d097e47079d6d5fcaa4a11518",
            "max": 20148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82a15b52d26643e2a8e6a1e2b3a15eac",
            "value": 20148
          }
        },
        "4bec223742e348fd9086eea5a03ef7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_444e04d032354e7786d9f980b66c47a5",
            "placeholder": "​",
            "style": "IPY_MODEL_1d4c1cd205b64470a7fc79d593776365",
            "value": " 20148/20148 [00:26&lt;00:00, 435.79it/s]"
          }
        },
        "9b4860c1bb84481fa3b9a252c6dd9b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97f729f849f4f89adc8b64355d2e502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc093ff4dc624ec18b5e78153687eaa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ece0198d097e47079d6d5fcaa4a11518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a15b52d26643e2a8e6a1e2b3a15eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "444e04d032354e7786d9f980b66c47a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d4c1cd205b64470a7fc79d593776365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}